{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samstone/ML/torchsig/torchsig/datasets/sig53.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchsig\n",
    "import torchaudio\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torchaudio.io import StreamReader\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = StreamReader( src=\":2\",format=\"avfoundation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stream.get_src_stream_info(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.add_basic_audio_stream(\n",
    "    frames_per_chunk=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(stream.num_out_streams):\n",
    "    print(stream.get_out_stream_info(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = next(stream.stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = chunks[0]\n",
    "chunk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.fft.fft(chunk[:,0])\n",
    "print(X.shape)\n",
    "\n",
    "mag_X = torch.abs(torch.fft.fftshift(X))\n",
    "print(mag_X.shape)\n",
    "plt.plot(20*torch.log10(mag_X[:,0]))\n",
    "plt.hold(True)\n",
    "plt.plot(20*torch.log10(mag_X[:,1]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(chunk[:,0])\n",
    "plt.figure()\n",
    "plt.plot(chunk[:,1])\n",
    "plt.figure()\n",
    "plt.plot(chunk[:,0] - chunk[:,1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "samples = 512\n",
    "frames = 256\n",
    "\n",
    "class Spectrogram():\n",
    "    def __init__(self,samples,frames):\n",
    "        self.spect = torch.zeros((frames,samples))\n",
    "    def update(self,x):\n",
    "        # Compute fft for samples\n",
    "        X = torch.fft.fftshift(torch.fft.fft(x))\n",
    "\n",
    "        # roll the buffer\n",
    "        self.spect = torch.roll(self.spect,shifts = (-1,0), dims=(0,1))\n",
    "        \n",
    "        # Set the first row to our new data\n",
    "        self.spect[0,:] = X\n",
    "\n",
    "# Form a circular buffer\n",
    "spect = Spectrogram(samples,frames)\n",
    "\n",
    "# Setup the streams \n",
    "streamer = StreamReader( src=\":2\",format=\"avfoundation\")\n",
    "streamer.add_basic_audio_stream(\n",
    "    frames_per_chunk=samples,\n",
    ")\n",
    "\n",
    "N = 4096\n",
    "# Set up loop to read in first N chunks \n",
    "for chunk in itertools.islice(stream, N):\n",
    "    spect.update(chunks[0][:,0])\n",
    "\n",
    "# x = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8]).view(4, 2)\n",
    "# print(x)\n",
    "# print(x.shape)\n",
    "# torch.roll(x, shifts=(1, 0), dims=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.utils.ffmpeg_utils.get_input_devices() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchsig\n",
    "import torchaudio\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torchaudio.io import StreamReader\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 2048\n",
    "# Setup the streams \n",
    "streamer = StreamReader( src=\":2\",format=\"avfoundation\")\n",
    "streamer.add_basic_audio_stream(\n",
    "    frames_per_chunk=samples,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stream_info = streamer.get_src_stream_info(0)\n",
    "sample_rate = stream_info.sample_rate\n",
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.CustomWindows.rectangular_window(window_size)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomWindows:\n",
    "    @staticmethod\n",
    "    def rectangular_window(window_size):\n",
    "        return [1,2,3,4]\n",
    "\n",
    "getattr(CustomWindows,'rectangular_window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hann\n",
      "tensor([0.0000, 0.0955, 0.3455, 0.6545, 0.9045, 1.0000, 0.9045, 0.6545, 0.3455,\n",
      "        0.0955])\n",
      "Kaiser\n",
      "tensor([0.0059, 0.0797, 0.2772, 0.5834, 0.8774, 1.0000, 0.8774, 0.5834, 0.2772,\n",
      "        0.0797])\n",
      "Rectangular\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "foo",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRectangular\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(m\u001b[39m.\u001b[39mrectangular_window(\u001b[39m10\u001b[39m))\n\u001b[0;32m---> 29\u001b[0m \u001b[39mprint\u001b[39m(m\u001b[39m.\u001b[39;49mfoo())\n\u001b[1;32m     30\u001b[0m m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\n",
      "Cell \u001b[0;32mIn[120], line 17\u001b[0m, in \u001b[0;36mCustomWindows.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__window_functions[item],item)\n\u001b[1;32m     16\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(item)\n",
      "\u001b[0;31mAttributeError\u001b[0m: foo"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "class CustomWindows(object):\n",
    "    def __init__(self):\n",
    "        self.__window_functions = {\n",
    "            \"bartlett_window\" : torch,\n",
    "            \"blackman_window\" : torch,\n",
    "            \"hamming_window\" : torch,\n",
    "            \"hann_window\" : torch,\n",
    "            \"kaiser_window\" : torch,\n",
    "        }\n",
    "    def __str__(self):\n",
    "        return str(list(self.__window_functions.keys()))\n",
    "    def __getattr__(self,item):\n",
    "        if item in self.__window_functions:\n",
    "            return getattr(self.__window_functions[item],item)\n",
    "        else:\n",
    "            raise AttributeError(item)\n",
    "    @staticmethod\n",
    "    def rectangular_window(window_size):\n",
    "        return torch.ones(window_size)\n",
    "    \n",
    "m = CustomWindows()\n",
    "print('Hann')\n",
    "print(m.hann_window(10))\n",
    "print('Kaiser')\n",
    "print(m.kaiser_window(10,True,7))\n",
    "print(\"Rectangular\")\n",
    "print(m.rectangular_window(10))\n",
    "print(m.foo())\n",
    "m.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextCacher:\n",
    "    \"\"\"Cache the end of input data and prepend the next input data with it.\n",
    "\n",
    "    Args:\n",
    "        segment_length (int): The size of main segment.\n",
    "            If the incoming segment is shorter, then the segment is padded.\n",
    "        context_length (int): The size of the context, cached and appended.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segment_length: int, context_length: int):\n",
    "        self.segment_length = segment_length\n",
    "        self.context_length = context_length\n",
    "        self.context = torch.zeros([context_length])\n",
    "\n",
    "    def __call__(self, chunk: torch.Tensor):\n",
    "        if chunk.size(0) < self.segment_length:\n",
    "            chunk = torch.nn.functional.pad(chunk, (0, self.segment_length - chunk.size(0)))\n",
    "        chunk_with_context = torch.cat((self.context, chunk))\n",
    "        self.context = chunk[-self.context_length :]\n",
    "        return chunk_with_context\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Window:\n",
    "    @staticmethod\n",
    "    def \n",
    "\n",
    "class Spectrogram:\n",
    "    def __init__(self,samples,frames,n_zp=2,window='rectangular'):\n",
    "        self.spect = torch.zeros((frames,samples))\n",
    "        self.n_zp = n_zp\n",
    "        self.fft_size = n_zp * samples\n",
    "        self.set_window(window)\n",
    "\n",
    "    def __call__(self,x):\n",
    "        self._update(x)\n",
    "\n",
    "    def set_window(self,window):\n",
    "        # Options are \n",
    "        # - bartlett_window\n",
    "        # - blackman_window\n",
    "        # - hamming_window\n",
    "        # - hann_window\n",
    "        # - kaiser_window\n",
    "        # - rectangular_window\n",
    "\n",
    "    def _update(self,x):\n",
    "        # Compute fft for samples\n",
    "        X = torch.fft.fftshift(torch.fft.fft(x))\n",
    "\n",
    "        # roll the buffer\n",
    "        self.spect = torch.roll(self.spect,shifts = (-1,0), dims=(0,1))\n",
    "        \n",
    "        # Set the first row to our new data\n",
    "        self.spect[0,:] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a circular matrix to store the spectrogram\n",
    "# To minimize latency, we apply the FFT without overlap for now\n",
    "# <TODO> add STFT overlap with OLS \n",
    "\n",
    "chunk_length = 1024\n",
    "frames_to_show = 4096\n",
    "spect = Spectrogram(chunk_length,frames_to_show)\n",
    "\n",
    "def _plot(seg,num_iter,unit=25):\n",
    "    # pop the data matrix, adding out latest segment\n",
    "\n",
    "    fig,axes = plt.subplots(1,1)\n",
    "    axes[0].imshow(spec,aspect=\"auto\",origin=\"lower\")\n",
    "    # axes[0].tick_params(which='both',left=False,labelleft=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spect\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spect' is not defined"
     ]
    }
   ],
   "source": [
    "spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_iterator = streamer.stream()\n",
    "segment_length = samples\n",
    "context_length = segment_length/2\n",
    "\n",
    "cacher = ContextCacher(segment_length, context_length)\n",
    "\n",
    "state, hypothesis = None, None\n",
    "\n",
    "def _plot(feats, num_iter, unit=25):\n",
    "    unit_dur = segment_length / sample_rate * unit\n",
    "    num_plots = num_iter // unit + (1 if num_iter % unit else 0)\n",
    "    fig, axes = plt.subplots(num_plots, 1)\n",
    "    t0 = 0\n",
    "    for i, ax in enumerate(axes):\n",
    "        feats_ = feats[i*unit:(i+1)*unit]\n",
    "        t1 = t0 + segment_length / sample_rate * len(feats_)\n",
    "        feats_ = torch.cat([f[2:-2] for f in feats_])  # remove boundary effect and overlap\n",
    "        ax.imshow(feats_.T, extent=[t0, t1, 0, 1], aspect=\"auto\", origin=\"lower\")\n",
    "        ax.tick_params(which='both', left=False, labelleft=False)\n",
    "        ax.set_xlim(t0, t0 + unit_dur)\n",
    "        t0 = t1\n",
    "    fig.suptitle(\"MelSpectrogram Feature\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def run_inference(num_iter=100):\n",
    "    global state, hypothesis\n",
    "    chunks = []\n",
    "    feats = []\n",
    "    for i, (chunk,) in enumerate(stream_iterator, start=1):\n",
    "        segment = cacher(chunk[:, 0])\n",
    "        features, length = feature_extractor(segment)\n",
    "        hypos, state = decoder.infer(features, length, 10, state=state, hypothesis=hypothesis)\n",
    "        hypothesis = hypos[0]\n",
    "        transcript = token_processor(hypothesis[0], lstrip=False)\n",
    "        print(transcript, end=\"\", flush=True)\n",
    "\n",
    "        chunks.append(chunk)\n",
    "        feats.append(features)\n",
    "        if i == num_iter:\n",
    "            break\n",
    "\n",
    "    # Plot the features\n",
    "    _plot(feats, num_iter)\n",
    "    return IPython.display.Audio(torch.cat(chunks).T.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically update a plot in Jupyter \n",
    "%matplotlib inline\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "for i in range(10):\n",
    "    plt.plot(np.random.randn(100,1))\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # to generate random data\n",
    "import matplotlib.pyplot as plt # to make figure\n",
    "\n",
    "# optional (just for figure appearence)\n",
    "plt.style.use('seaborn-colorblind')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "print('library imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "MEASUREMENT_TIME = 50\n",
    "INTERVAL_SEC = 0.1\n",
    "\n",
    "for i in range(MEASUREMENT_TIME):\n",
    "    # replace with your data\n",
    "    data = np.random.rand(100)\n",
    "\n",
    "    plt.plot(data)\n",
    "\n",
    "    # figure appearence adjustments\n",
    "    plt.ylim(-0.2, 1.2)\n",
    "    plt.title(f'FRAME {i+1}')\n",
    "\n",
    "    # to avoid clearing last plot\n",
    "    if (i != MEASUREMENT_TIME-1):\n",
    "        plt.draw()\n",
    "        plt.pause(INTERVAL_SEC)\n",
    "        plt.cla()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(100,1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
